{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Executive Summary (To be done)\n\nG. Provide an executive summary of your findings, including the rationale of choosing the model you chose, iterations, etc. 10 points\n\nThis is separate from the explanation and logic mentioned above. he Executive summary is a brief report on your entire project in less than 1000 words (loosely). Use paragraphs, headings, bullet points, numerical data to your advantage. You should include:\n\nThe business question in brief\nAny important methodological steps or decisions\nKey findings\nYour model including rationale, iterations, etc.\nYour final conclusions and actionable recommendations.\nYou can also refer to any key figure or table in this section (re-insert the table within the executive summary in that case). This really is the crux of business communication, so take some time in crafting this. ","metadata":{"execution":{"iopub.status.busy":"2023-06-01T02:01:18.035134Z","iopub.execute_input":"2023-06-01T02:01:18.035542Z","iopub.status.idle":"2023-06-01T02:01:18.070253Z","shell.execute_reply.started":"2023-06-01T02:01:18.035512Z","shell.execute_reply":"2023-06-01T02:01:18.069124Z"}}},{"cell_type":"markdown","source":"# Dataset Description\nThe dataset consists of 41.2 thousand valid entries, comprising various personal, economic, and contact-related attributes, such as age, employment, education, housing, loans, communication types, and campaign-related details. It spans a wide age range from 17 to 98 years, with the majority being administrators and blue-collar workers. Most of the individuals hold a university degree and do not have any default credits. The dataset indicates a majority of the individuals are married and have been contacted via cell phones. The month of May, Thursdays, and Mondays are the most common times for contact. Pertaining to economic indicators, the dataset includes consumer price and confidence indices and the Euribor 3-month rate.\n\nThe following table lays out specific statistics for each category:\n\n| Category                           | Statistics                                            | Type          |\n| ---------------------------------- | ----------------------------------------------------- | ----------------|\n| Age                                | 17 - 98 Mean: 40, Std. Dev: 10.4, Mode: 29.15, 33.20 | Continuous    |\n| Employment                         | 25% Administrators, 22% Blue-Collar, Others varied   | Categorical   |\n| Education                          | 30% University Degree, 23% High School                | Categorical   |\n| Credit Default                     | 79% No Default                                        | Binary        |\n| Housing                            | 52% Have Loans, 45% No Loans                          | Binary        |\n| Personal Loans                     | 15% Have Loans, 82% No Loans                          | Binary        |\n| Marital Status                     | 61% Married, 28% Single                               | Categorical   |\n| Communication Type                 | 63% Cell Phones, 37% Telephone                        | Binary        |\n| Contact Month                      | Most common: May 33%                                  | Categorical   |\n| Contact Day                        | Most common: Thursdays, Mondays 21%                   | Categorical   |\n| Number of Employees                | 4964 - 5228 Mean: 5170                                | Continuous    |\n| Term Deposit Subscription ('y')    | 11.3% Yes, 88.7% No                                   | Binary        |\n| Call Duration (Seconds)            | 0 - 4918 Average: 258                                 | Continuous    |\n| Contact Frequency in Current Campaign | Most individuals contacted less than 3.75 times   | Continuous    |\n| 'pdays'                            | Majority were not previously contacted                 | Continuous    |\n| 'previous'                         | Majority were not contacted in previous campaigns      | Continuous    |\n| 'poutcome'                         | No previous campaign for 86% of cases                  | Categorical   |\n| Consumer Price Index               | 92.2 - 94.8 Mean: 93.6                                | Continuous    |\n| Consumer Confidence Index          | 50.8 - 26.9 Mean: 40.5                                | Continuous    |\n| 'euribor3m' (3-month Euribor interest rate) | Average: 3.62                                  | Continuous    |\n","metadata":{}},{"cell_type":"markdown","source":"# Business Question\nBecause the dataset contains a wide variety of indicators and demographic data, such as job, campaign, economic, subscription, and loan data, bank executives can make many decisions and answer numerous questions.\n\nFor example, assessment of marketing campaign effectiveness would be an important metric to measure and would allow the company to adjust their strategies in accordance with the findings. They would be able to identify which demographics have a propensity to subscribe to their term deposit and therefore help create an effective and targeted marketing strategy. They could also investigate how economic variables play into their campaigns, such as how employment rates affect term deposits.\nChoosing from a few of these many metrics, a realistic business question that can be asked is ”How effective are our campaigns for people who have been previously contacted?\" By comparing the 'previous' (number of contacts before this campaign) and 'y' variables, the bank can begin to determine the effectiveness of their recurring marketing efforts.\n\nOnce preliminary findings have been established, further analysis can be done to determine if other variables such as age and occupation play a role as well.\n\n# Outcome Variable\n\nFrom the question highlighted above, the outcome variable for this analysis will be 'y', representing whether or not a person has subscribed to a term deposit. The primary independent variable of interest will be 'previous', indicating the number of previous contacts performed with a person.\nThe 'previous' variable provides a measure of past engagement with a person. By comparing the subscription rate ('y') among those who have been previously contacted (i.e., 'previous' > 0 and those who haven't (i.e., 'previous' = 0, we can assess the effectiveness of our campaigns among those who have been previously contacted.\n\nFor example, if it turns out that the subscription rate is significantly higher among those who have been previously contacted, it would suggest that our campaigns are more effective when we have an existing relationship with the person. On the other hand, if there is no significant difference in the subscription rate, it could suggest that the number of previous contacts does not have a strong impact on the effectiveness of our campaigns.","metadata":{}},{"cell_type":"markdown","source":"# Prediction Method\nWhen it comes to choosing between Logistic Regression or Decision Trees for our question at hand, the most ideal method would be the Decision Tree model.\nReasoning for this decision include these strengths of the Decision Tree:\n1. **Categorical Handling:** Categorical variables are a built-in feature with Decision Trees, and because the dataset contains many categories, it would be most compatible with this model.\n2. **Interpretability:** Decision trees are opinionated and offer clear,concise rules. This allows for easy interpretability when we use the model to make predictions about campaign effectiveness \u0000Bock).\n3. **Interaction Handling:** Decision Trees can account for interactions between multiple variables, which would be beneficial when looking to see how economic variables affect term loan rates. For example, it would be of interest to look into the role of age and occupation in tandem with the number of previous contacts.\nThat having been said, a flaw that Decision Trees exhibit is that they’re prone to overfitting \u0000Kunani). It can be mitigated by maintaining a shorter tree or setting constraints on the maximum depth and/or minimum samples per leaf. Additionally, while Logistic Regression might not be an ideal choice for the question at hand, it’s a popular and useful method for simple classification.","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Analysis\n\n## Initializing\n\n#### Importing Libraries\nThe script starts by importing several useful Python libraries:\n- pandas for data handling and manipulation,\n- seaborn and matplotlib.pyplot for data visualization. \n\nThese libraries are commonly used in data science and analytics for working with data and creating visualizations.\n\n#### Iterating Over Files in a Directory\nThe script uses os.walk() function to iterate over all the directories and files under the specified path ('/kaggle/input'). The function generates the file names in a directory tree by walking the tree either top-down or bottom-up.\nFor each directory in the tree rooted at directory top (including top itself), it yields a 3-tuple (dirpath, dirnames, filenames).\n- dirpath is a string, the path to the directory.\n- dirnames is a list of the names of the subdirectories in dirpath (excluding '.' and '..').\n- filenames is a list of the names of the non-directory files in dirpath.\n\nThe os.path.join(dirname, filename) command is then used to print the full file path for every file found in the walk.","metadata":{}},{"cell_type":"code","source":"# Initializing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom tabulate import tabulate\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-03T18:57:48.555111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the Data (To be done)\n\nWe will be utilizing this following Python code snippet as part of our initial exploratory data analysis when encountering a new dataset. The script makes use of the pandas library, an essential tool in our data science kit, which aids in efficient data manipulation and analysis. Right now, the main focus is to gain a rough understanding of the data's main statistical indicators. From this, we can begin planning which indicators might be the most important or useful for anwsering the question at hand.","metadata":{}},{"cell_type":"code","source":"# Defining \"df\" and displaying significant values\ndf = pd.read_csv('/kaggle/input/dataset-for-bta-419-2023/BTA_419_2023_Data.csv')\ndf.head()\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the Data\n\nThe following figure was run to analyze the correlation between different numerical variables in the dataframe 'df'. Correlation provides an indication of how related two variables might be. It can be a useful tool to identify the relationships between variables, which can be critical in many situations like feature selection, multivariate analysis, and model building in predictive analytics.","metadata":{}},{"cell_type":"code","source":"# Analyzing relationships\ncorrelation = df.corr(numeric_only=True)\nplt.figure(figsize=(10,8))\nsns.heatmap(correlation, annot=True, cmap='coolwarm')\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see in the heatmap above, there appears to be some highly inter-correlated variables. Specifically, emp.var.rate, cons.price.idx, euribor3m, and nr.employed all have a strong correlation between one another. Having just learned this, we will take these findings in the next step and use it for our model.","metadata":{}},{"cell_type":"markdown","source":"## Defining the Decision Tree Model\n\nIn order to predict the outcome variable 'y' (Term Deposit Subscription), we will be using the Decision Tree model. The reasons for this have been previously mentioned - namely, its effectiveness with categorical variables, interpretability, and ability to handle multiple variable interactions. We will focus on the following predictors:\n\n**'emp.var.rate'**: represents the quarterly change in employment levels, indicating the fluctuation in the number of people employed within a region or country.\n\n**'cons.price.idx'**: reflects the average change in prices of goods and services consumed by households, serving as a measure of inflation and cost of living.\n\n**'euribor3m'**: the interest rate at which European banks offer unsecured loans to one another in the euro currency for a three-month period, serving as a benchmark for various financial transactions.\n\n**'nr.employed'**: denotes the total count of employees within a region or country, providing insights into the size of the workforce and labor market conditions.","metadata":{}},{"cell_type":"markdown","source":"## Creating the Model","metadata":{}},{"cell_type":"code","source":"# Selecting variables for prediction \nselected_features = ['nr.employed', 'euribor3m', 'emp.var.rate', 'cons.price.idx']\n\n# Creating Dummy Variables for Categorical Features\ndf_dummies = pd.get_dummies(df[selected_features])\n\n# Predictor and Target Variables\nX = df_dummies\ny = df['y']\n\n# Train Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Defining the Decision Tree Model\ntree = DecisionTreeClassifier(max_depth=3, random_state=42)\n\n# Fitting the model\ntree.fit(X_train, y_train)\n\n# Predicting the test set results\ny_pred = tree.predict(X_test)\n\n# Classification Report\nprint(classification_report(y_test, y_pred))\n\n# Accuracy Score\nprint('Accuracy Score:', accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nplt.figure(figsize=(10,7))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# Analyzing the feature importances\nimportances = tree.feature_importances_\nfeature_names = X.columns\n\n# Create a DataFrame to view the importances\nimportance_df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n\nprint(tabulate(importance_df, headers='keys', tablefmt='psql'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Description\n\n### About the Model\n\nThe final model employed in this task is a Decision Tree Classifier, a powerful machine learning algorithm used for both classification and regression purposes. Decision Tree Classifier creates a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n\n#### Predictors Used\n\nThe predictors used in this model are:\n\n'nr.employed': This is the number of employees. It can be an indicator of the company's size and could affect the outcome being predicted.\n'euribor3m': This is the Euribor 3 month rate, which is a standard financial indicator used in European markets. It can have a significant influence on the company's financial capabilities.\n'emp.var.rate': This is the employment variation rate. Fluctuations in the employment rate could signify changes in the overall business environment and economic health.\n'cons.price.idx': This is the consumer price index, an indicator of the inflation trend within an economy. It affects the purchasing power of consumers and can thus affect business operations.\nEvaluation of the Model\n\nThe model's performance was evaluated using different metrics:\n\nClassification Report: It provides precision, recall, and F1-score for each class. The precision is a measure of how many positive predictions were actually correct. Recall indicates how many actual positives the model managed to capture. The F1-score is a balanced representation of precision and recall.\nAccuracy Score: It is the fraction of correct predictions made by the model. For our model, the accuracy score is approximately 0.89.\nConfusion Matrix: It's a table used to describe the performance of a classification model. The confusion matrix visualized here shows the true positives, true negatives, false positives, and false negatives.\nEffect of Predictors on the Outcome\n\nThe effect of predictors on the outcome is gauged by the feature importances. Feature importance gives a score for each feature of the data, with the higher the score, the more important or relevant the feature towards the output variable.\n\nAs it stands, the model appears to have significant room for improvement, specifically in its performance predicting 'yes' outcomes. A potential solution could be to implement a more balanced dataset or to fine-tune the model's parameters. Further analysis of the feature importances might also help in refining the model for better performance.\n\n#### Thought Process:\n\nSelection of variables: The selection of the variables is based on their relevance to the economic condition, which could significantly impact the outcome we're trying to predict. For example, the number of employees might indicate the size and stability of a business, the Euribor rate could influence the business's ability to borrow and invest, the employment variation rate might reflect the labor market conditions, and the consumer price index could show the general economic climate. This combination of variables is likely to capture different aspects of economic conditions that may have an effect on the outcome variable.\n\nEvaluation of the model: The model was evaluated using a classification report, an accuracy score, and a confusion matrix. The accuracy score is approximately 0.89, which means that the model correctly predicted 89% of the instances. The precision for 'no' is 0.91 and for 'yes' is 0.53, suggesting the model is more accurate when predicting 'no'. The recall for 'no' is higher (0.97) compared to 'yes' (0.26), meaning that the model is able to capture a higher percentage of actual 'no' instances. The F1-score, a weighted average of precision and recall, is higher for 'no' predictions (0.94) compared to 'yes' predictions (0.35).\n\nEffect of the predictors on the outcome: From the feature importance evaluation, we can see how each variable contributed to the predictions. This will help us understand the role of each variable in the model. However, it's important to note that the 'importance' values are based on how much nodes using that feature reduce impurity on average (across all trees in the forest). They don't necessarily mean that a feature is highly discriminative between classes.\n\nOverall, the chosen variables and model seemed to work well for this prediction task, with a good accuracy score. The model, however, seems to be better at predicting 'no' outcomes than 'yes' outcomes, which could be an area for improvement. We could try different models or adjust the current one by tuning its parameters or by balancing the classes in our data.","metadata":{}},{"cell_type":"markdown","source":"# Works Cited\nBock, Tim. “Decision Trees Are Usually Better Than Logistic Regression.” Displayr,\nhttps://www.displayr.com/decision-trees-are-usually-better-than-logistic -regression/. Accessed 20 May 2023.\n\nEuribor Rates. Euribor rates - all information on Euribor, https://www.euribor-rates.eu/en/. Accessed 19 May 2023.\n\nKunani, R. “Decision Trees and Random Forests.” HackMD, https://hackmd.io/@rkunani/decision-tree. Accessed 20 May 2023.","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:00:59.106436Z","iopub.execute_input":"2023-05-25T00:00:59.106869Z","iopub.status.idle":"2023-05-25T00:00:59.116225Z","shell.execute_reply.started":"2023-05-25T00:00:59.106828Z","shell.execute_reply":"2023-05-25T00:00:59.114537Z"}}}]}